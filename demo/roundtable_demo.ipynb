{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "- I want to demonstrate how we think about building LLM powered tools\n",
    "\n",
    "- The demo is a POC for AI powered e2e testing tool, **NOT A PRODUCT**\n",
    "\n",
    "- I'll be using Serenity as the example app being tested\n",
    "\n",
    "  - sure you know it since Rob is regular on these roundtables\n",
    "  - the test scenario is just to sign in to the app and make sure we can send a message\n",
    "\n",
    "- it's not production ready, but:\n",
    "  - already it is a very **powerful tool for exploratory testing**\n",
    "  - it's a great starting point for building a test suite **(0-80 rather than 80-100)**\n",
    "  - it's a great way to document the test scenarios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat based API\n",
    "\n",
    "- it unlocks better models, function calling etc.\n",
    "\n",
    "- but more importantly it gives the LLM a temporal dimension\n",
    "\n",
    "  - it's not necessarily that I want to chat with the model/agent, but it's a stream of events (i did this, the API responded with this, I asked the user this, etc...)\n",
    "\n",
    "- interface is a bit rough, but it's **aiming at developers**, and optimizes for **rapid iteration** (trying things and seeing what works)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System message\n",
    "\n",
    "- gives the LLM agent a role, gives it rules, boundaries, instructions on how to behave and so on\n",
    "\n",
    "- it's usually static for a single session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are a QA engineer controlling a browser. Your goal is to plan and go through a test scenario with the user. Always ask the user for any information you need to input, like URLs, credentials or other data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User prompt\n",
    "\n",
    "- this is an input of the operator into the system\n",
    "\n",
    "- In the ideal case, the first prompt could be a JIRA ticket describing what needs to be tested, can be non-technical, doesn't require knowledge of the app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a test for a chat app. We should test a user can send a message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context message\n",
    "\n",
    "- this is where we give the agent the current state of the world\n",
    "\n",
    "- we take HTML from the browser, strip it down so it doesn't cost too many tokens\n",
    "\n",
    "- but there could be anything\n",
    "\n",
    "  - we experimented with giving the agent a dynamic test plan, description of the page generated by another LLM, etc.\n",
    "  - you could provide pre-generated test-data here, e.g. if you want a database specifically prepared for the test case\n",
    "\n",
    "- the history of the interaction is sandwiched between the context and the system message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And finally the COMPLETION\n",
    "\n",
    "- this is what the agent generates, it can have content, which is the message for the user, and a function call, which is the agent requesting to call a function in the system\n",
    "\n",
    "- it's editable in the tool, this is where the rapid iteration comes in\n",
    "\n",
    "- ideally the agent generates the right completion on first try, but if we can re-run it, or modify it manually, it speeds up the process, and gives us great data for fine-tuning the model further, reducing cost and improving accuracy\n",
    "\n",
    "- We only commit the completion after we're happy with it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asks for URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dev.app.serenityapp.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asks for credentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viktor.nawrath+tester@profiq.com / TestPassword!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to wait for app to load\n",
    "\n",
    "- we generated the context message faster than the app loaded, we can just re-run to get the most recent state of the browser\n",
    "\n",
    "- we use playwright in th background, which has auto-wait, so this is not an issue in the generated test case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asks for the message content\n",
    "\n",
    "- we can let it generate a random message. This is awesome when you have long user forms that you want to fill in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can put in whatever.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save conversation and generate test case\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
